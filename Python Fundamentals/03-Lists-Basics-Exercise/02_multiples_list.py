factor = int(input())
count = int(input())

multiplies = []

for num in range(1, count + 1):
    multiplies.append(num * factor)

print(multiplies)